{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjmousavi97/Computer-Vision/blob/main/projects/pro-005/src/squeezNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8NGouVpJ4DNN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IuCIfrfs6e_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d48546-1b11-49bb-ba9b-b56dac4b4998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h0mEyQYH6k4J"
      },
      "outputs": [],
      "source": [
        "# Transforms for training and validation\n",
        "data_transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P4aPvD9c6lVJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "2657d009-5559-4047-c800-24512e9357c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmohammadjavad-mousavi97\u001b[0m (\u001b[33mmohammadjavad-mousavi97-arak-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260101_184338-11x33j9j</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mohammadjavad-mousavi97-arak-university/SqueesNet-5flowers/runs/11x33j9j' target=\"_blank\">true-tree-3</a></strong> to <a href='https://wandb.ai/mohammadjavad-mousavi97-arak-university/SqueesNet-5flowers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mohammadjavad-mousavi97-arak-university/SqueesNet-5flowers' target=\"_blank\">https://wandb.ai/mohammadjavad-mousavi97-arak-university/SqueesNet-5flowers</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mohammadjavad-mousavi97-arak-university/SqueesNet-5flowers/runs/11x33j9j' target=\"_blank\">https://wandb.ai/mohammadjavad-mousavi97-arak-university/SqueesNet-5flowers/runs/11x33j9j</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.init(\n",
        "    project=\"SqueesNet-5flowers\", config={\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"epochs\": 50,\n",
        "    \"batch_size\": 16,\n",
        "    \"architecture\": \"SqueesNet\",\n",
        "    \"dataset\": \"5flowers\",\n",
        "    \"pretrained\": True,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"input_size\": 224\n",
        "    }\n",
        ")\n",
        "\n",
        "config = wandb.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PLsDbeeq9z3A"
      },
      "outputs": [],
      "source": [
        "train_dir = \"/content/drive/MyDrive/Colab Notebooks/flowers/train\"\n",
        "val_dir = \"/content/drive/MyDrive/Colab Notebooks/flowers/val\"\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=data_transform['train'])\n",
        "val_dataset = datasets.ImageFolder(val_dir, transform=data_transform['val'])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Nu1g5tmy7qSE"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import SqueezeNet1_1_Weights\n",
        "\n",
        "model = models.squeezenet1_1(weights=SqueezeNet1_1_Weights.DEFAULT)\n",
        "model.classifier[1] = nn.Conv2d(in_channels=512, out_channels=5, kernel_size=(1, 1))\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.classifier[1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "wandb.watch(model, log=\"all\", log_freq=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I1wql9kWxiAr"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "inywtY_OxlzX"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10, log_every=10):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for step, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            bs = labels.size(0)\n",
        "            running_loss += loss.item() * bs\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += bs\n",
        "\n",
        "            if (step + 1) % log_every == 0:\n",
        "                train_loss_step = running_loss / max(1, total)\n",
        "                train_acc_step = correct / max(1, total)\n",
        "                wandb.log(\n",
        "                    {\n",
        "                        \"epoch\": epoch + 1,\n",
        "                        \"step\": epoch * len(train_loader) + (step + 1),\n",
        "                        \"train/loss\": train_loss_step,\n",
        "                        \"train/acc\": train_acc_step,\n",
        "                        \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "                    }\n",
        "                )\n",
        "\n",
        "        train_loss = running_loss / max(1, total)\n",
        "        train_acc = correct / max(1, total)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss_sum = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images = images.to(device, non_blocking=True)\n",
        "                labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                bs = labels.size(0)\n",
        "                val_loss_sum += loss.item() * bs\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += bs\n",
        "\n",
        "        val_loss = val_loss_sum / max(1, val_total)\n",
        "        val_acc = val_correct / max(1, val_total)\n",
        "\n",
        "        wandb.log(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"train/loss_epoch\": train_loss,\n",
        "                \"train/acc_epoch\": train_acc,\n",
        "                \"val/loss\": val_loss,\n",
        "                \"val/acc\": val_acc,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "            f\"train_loss={train_loss:.4f} train_acc={train_acc:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} val_acc={val_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "    print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9yVBzUnIxw8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2692246c-894f-43ae-d305-c6e5bca8caf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | train_loss=0.6609 train_acc=0.7532 | val_loss=0.4298 val_acc=0.8497\n",
            "Epoch 2/50 | train_loss=0.3815 train_acc=0.8660 | val_loss=0.4004 val_acc=0.8605\n",
            "Epoch 3/50 | train_loss=0.3397 train_acc=0.8787 | val_loss=0.3629 val_acc=0.8773\n",
            "Epoch 4/50 | train_loss=0.2956 train_acc=0.8945 | val_loss=0.4145 val_acc=0.8477\n",
            "Epoch 5/50 | train_loss=0.2721 train_acc=0.9059 | val_loss=0.3829 val_acc=0.8764\n",
            "Epoch 6/50 | train_loss=0.2547 train_acc=0.9109 | val_loss=0.3276 val_acc=0.8872\n",
            "Epoch 7/50 | train_loss=0.2421 train_acc=0.9149 | val_loss=0.3347 val_acc=0.8942\n",
            "Epoch 8/50 | train_loss=0.2414 train_acc=0.9092 | val_loss=0.3525 val_acc=0.8823\n",
            "Epoch 9/50 | train_loss=0.2292 train_acc=0.9182 | val_loss=0.3234 val_acc=0.8971\n",
            "Epoch 10/50 | train_loss=0.2130 train_acc=0.9232 | val_loss=0.3399 val_acc=0.8843\n",
            "Epoch 11/50 | train_loss=0.2073 train_acc=0.9299 | val_loss=0.3047 val_acc=0.9060\n",
            "Epoch 12/50 | train_loss=0.2087 train_acc=0.9217 | val_loss=0.3052 val_acc=0.9120\n",
            "Epoch 13/50 | train_loss=0.1981 train_acc=0.9296 | val_loss=0.3252 val_acc=0.9011\n",
            "Epoch 14/50 | train_loss=0.2135 train_acc=0.9227 | val_loss=0.3291 val_acc=0.8991\n",
            "Epoch 15/50 | train_loss=0.2021 train_acc=0.9296 | val_loss=0.3225 val_acc=0.9060\n",
            "Epoch 16/50 | train_loss=0.2002 train_acc=0.9299 | val_loss=0.3175 val_acc=0.9060\n",
            "Epoch 17/50 | train_loss=0.1781 train_acc=0.9364 | val_loss=0.3172 val_acc=0.9050\n",
            "Epoch 18/50 | train_loss=0.1907 train_acc=0.9311 | val_loss=0.3275 val_acc=0.9060\n",
            "Epoch 19/50 | train_loss=0.1740 train_acc=0.9379 | val_loss=0.3002 val_acc=0.9100\n",
            "Epoch 20/50 | train_loss=0.1802 train_acc=0.9324 | val_loss=0.3085 val_acc=0.9041\n",
            "Epoch 21/50 | train_loss=0.1788 train_acc=0.9341 | val_loss=0.3247 val_acc=0.9011\n",
            "Epoch 22/50 | train_loss=0.1775 train_acc=0.9376 | val_loss=0.3372 val_acc=0.8961\n",
            "Epoch 23/50 | train_loss=0.1708 train_acc=0.9371 | val_loss=0.3441 val_acc=0.8912\n",
            "Epoch 24/50 | train_loss=0.1647 train_acc=0.9401 | val_loss=0.3175 val_acc=0.9001\n",
            "Epoch 25/50 | train_loss=0.1628 train_acc=0.9441 | val_loss=0.3490 val_acc=0.8922\n",
            "Epoch 26/50 | train_loss=0.1703 train_acc=0.9339 | val_loss=0.3561 val_acc=0.9090\n",
            "Epoch 27/50 | train_loss=0.1672 train_acc=0.9396 | val_loss=0.3335 val_acc=0.8892\n",
            "Epoch 28/50 | train_loss=0.1727 train_acc=0.9409 | val_loss=0.3286 val_acc=0.9130\n",
            "Epoch 29/50 | train_loss=0.1512 train_acc=0.9464 | val_loss=0.3225 val_acc=0.9050\n",
            "Epoch 30/50 | train_loss=0.1601 train_acc=0.9434 | val_loss=0.3165 val_acc=0.9179\n",
            "Epoch 31/50 | train_loss=0.1533 train_acc=0.9466 | val_loss=0.3181 val_acc=0.9050\n",
            "Epoch 32/50 | train_loss=0.1525 train_acc=0.9454 | val_loss=0.3911 val_acc=0.8843\n",
            "Epoch 33/50 | train_loss=0.1457 train_acc=0.9499 | val_loss=0.3350 val_acc=0.9041\n",
            "Epoch 34/50 | train_loss=0.1761 train_acc=0.9356 | val_loss=0.3243 val_acc=0.9041\n",
            "Epoch 35/50 | train_loss=0.1511 train_acc=0.9449 | val_loss=0.3276 val_acc=0.9060\n",
            "Epoch 36/50 | train_loss=0.1643 train_acc=0.9419 | val_loss=0.3349 val_acc=0.9060\n",
            "Epoch 37/50 | train_loss=0.1465 train_acc=0.9476 | val_loss=0.3825 val_acc=0.8961\n",
            "Epoch 38/50 | train_loss=0.1529 train_acc=0.9469 | val_loss=0.3603 val_acc=0.8902\n",
            "Epoch 39/50 | train_loss=0.1566 train_acc=0.9449 | val_loss=0.3484 val_acc=0.9090\n",
            "Epoch 40/50 | train_loss=0.1635 train_acc=0.9426 | val_loss=0.3416 val_acc=0.9031\n",
            "Epoch 41/50 | train_loss=0.1550 train_acc=0.9479 | val_loss=0.3434 val_acc=0.9021\n",
            "Epoch 42/50 | train_loss=0.1576 train_acc=0.9404 | val_loss=0.3169 val_acc=0.9001\n",
            "Epoch 43/50 | train_loss=0.1483 train_acc=0.9474 | val_loss=0.3496 val_acc=0.9011\n",
            "Epoch 44/50 | train_loss=0.1636 train_acc=0.9384 | val_loss=0.3610 val_acc=0.8961\n",
            "Epoch 45/50 | train_loss=0.1497 train_acc=0.9494 | val_loss=0.3319 val_acc=0.9130\n",
            "Epoch 46/50 | train_loss=0.1480 train_acc=0.9429 | val_loss=0.3550 val_acc=0.9060\n",
            "Epoch 47/50 | train_loss=0.1494 train_acc=0.9454 | val_loss=0.3258 val_acc=0.9090\n",
            "Epoch 48/50 | train_loss=0.1274 train_acc=0.9523 | val_loss=0.3483 val_acc=0.9070\n",
            "Epoch 49/50 | train_loss=0.1574 train_acc=0.9426 | val_loss=0.3381 val_acc=0.9080\n",
            "Epoch 50/50 | train_loss=0.1520 train_acc=0.9451 | val_loss=0.3223 val_acc=0.9130\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=config.epochs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dtle48881bVy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM7UrudG8i1mGJ3JTdBMoMf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}